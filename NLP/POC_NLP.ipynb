{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_table(r'C:\\Users\\gaurav\\Desktop\\new\\movie_rating\\train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_table(r'C:\\Users\\gaurav\\Desktop\\new\\movie_rating\\test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   PhraseId    156060 non-null  int64 \n",
      " 1   SentenceId  156060 non-null  int64 \n",
      " 2   Phrase      156060 non-null  object\n",
      " 3   Sentiment   156060 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66292 entries, 0 to 66291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   PhraseId    66292 non-null  int64 \n",
      " 1   SentenceId  66292 non-null  int64 \n",
      " 2   Phrase      66292 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A series of escapades demonstrating the adage ...\n",
       "1    A series of escapades demonstrating the adage ...\n",
       "2                                             A series\n",
       "3                                                    A\n",
       "4                                               series\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Phrase'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    An intermittently pleasing but mostly routine ...\n",
       "1    An intermittently pleasing but mostly routine ...\n",
       "2                                                   An\n",
       "3    intermittently pleasing but mostly routine effort\n",
       "4           intermittently pleasing but mostly routine\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Phrase'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### remove accented characters :\n",
    "def remove_accented_chars(text):\n",
    "    \"\"\"remove accented characters from text, e.g. caf√©\"\"\"\n",
    "    text = unidecode.unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     A series of escapades demonstrating the adage ...\n",
       "1     A series of escapades demonstrating the adage ...\n",
       "2                                              A series\n",
       "3                                                     A\n",
       "4                                                series\n",
       "5     of escapades demonstrating the adage that what...\n",
       "6                                                    of\n",
       "7     escapades demonstrating the adage that what is...\n",
       "8                                             escapades\n",
       "9     demonstrating the adage that what is good for ...\n",
       "10                              demonstrating the adage\n",
       "11                                        demonstrating\n",
       "12                                            the adage\n",
       "13                                                  the\n",
       "14                                                adage\n",
       "15                      that what is good for the goose\n",
       "16                                                 that\n",
       "17                           what is good for the goose\n",
       "18                                                 what\n",
       "19                                is good for the goose\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Phrase']=train['Phrase'].apply(lambda x : remove_accented_chars(x))\n",
    "train['Phrase'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     An intermittently pleasing but mostly routine ...\n",
       "1     An intermittently pleasing but mostly routine ...\n",
       "2                                                    An\n",
       "3     intermittently pleasing but mostly routine effort\n",
       "4            intermittently pleasing but mostly routine\n",
       "5                           intermittently pleasing but\n",
       "6                               intermittently pleasing\n",
       "7                                        intermittently\n",
       "8                                              pleasing\n",
       "9                                                   but\n",
       "10                                       mostly routine\n",
       "11                                               mostly\n",
       "12                                              routine\n",
       "13                                               effort\n",
       "14                                                    .\n",
       "15    Kidman is really the only thing that 's worth ...\n",
       "16                                               Kidman\n",
       "17    is really the only thing that 's worth watchin...\n",
       "18    is really the only thing that 's worth watchin...\n",
       "19                                            is really\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Phrase']=test['Phrase'].apply(lambda x : remove_accented_chars(x))\n",
    "test['Phrase'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remove Punctuation:\n",
    "def remove_punc(text):\n",
    "    no_punc = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    return no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     A series of escapades demonstrating the adage ...\n",
       "1     A series of escapades demonstrating the adage ...\n",
       "2                                              A series\n",
       "3                                                     A\n",
       "4                                                series\n",
       "5     of escapades demonstrating the adage that what...\n",
       "6                                                    of\n",
       "7     escapades demonstrating the adage that what is...\n",
       "8                                             escapades\n",
       "9     demonstrating the adage that what is good for ...\n",
       "10                              demonstrating the adage\n",
       "11                                        demonstrating\n",
       "12                                            the adage\n",
       "13                                                  the\n",
       "14                                                adage\n",
       "15                      that what is good for the goose\n",
       "16                                                 that\n",
       "17                           what is good for the goose\n",
       "18                                                 what\n",
       "19                                is good for the goose\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Phrase']=train['Phrase'].apply(lambda x : remove_punc(x))\n",
    "train['Phrase'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     An intermittently pleasing but mostly routine ...\n",
       "1     An intermittently pleasing but mostly routine ...\n",
       "2                                                    An\n",
       "3     intermittently pleasing but mostly routine effort\n",
       "4            intermittently pleasing but mostly routine\n",
       "5                           intermittently pleasing but\n",
       "6                               intermittently pleasing\n",
       "7                                        intermittently\n",
       "8                                              pleasing\n",
       "9                                                   but\n",
       "10                                       mostly routine\n",
       "11                                               mostly\n",
       "12                                              routine\n",
       "13                                               effort\n",
       "14                                                     \n",
       "15    Kidman is really the only thing that s worth w...\n",
       "16                                               Kidman\n",
       "17    is really the only thing that s worth watching...\n",
       "18    is really the only thing that s worth watching...\n",
       "19                                            is really\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Phrase']=test['Phrase'].apply(lambda x : remove_punc(x))\n",
    "test['Phrase'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you',\n",
       "       \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself',\n",
       "       'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her',\n",
       "       'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n",
       "       'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n",
       "       'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
       "       'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
       "       'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
       "       'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n",
       "       'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
       "       'through', 'during', 'before', 'after', 'above', 'below', 'to',\n",
       "       'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n",
       "       'again', 'further', 'then', 'once', 'here', 'there', 'when',\n",
       "       'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
       "       'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
       "       'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will',\n",
       "       'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n",
       "       'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n",
       "       \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\",\n",
       "       'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma',\n",
       "       'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",\n",
       "       'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\",\n",
       "       'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')\n",
    "# displaying the stopwords\n",
    "np.array(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remove Stopwords:\n",
    "def stopwords(text):\n",
    "    '''a function for removing the stopword'''\n",
    "    # removing the stop words and lowercasing the selected words\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    # joining the list of words with space separator\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    series escapades demonstrating adage good goos...\n",
       "1      series escapades demonstrating adage good goose\n",
       "2                                               series\n",
       "3                                                     \n",
       "4                                               series\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Phrase']=train['Phrase'].apply(stopwords)\n",
    "train['Phrase'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    intermittently pleasing mostly routine effort\n",
       "1    intermittently pleasing mostly routine effort\n",
       "2                                                 \n",
       "3    intermittently pleasing mostly routine effort\n",
       "4           intermittently pleasing mostly routine\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Phrase']=test['Phrase'].apply(stopwords)\n",
    "test['Phrase'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Tokenize the sentence:\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [series, escapades, demonstrating, adage, good...\n",
       "1    [series, escapades, demonstrating, adage, good...\n",
       "2                                             [series]\n",
       "3                                                   []\n",
       "4                                             [series]\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Phrase']=train['Phrase'].apply(lambda x : tokenizer.tokenize(x.lower()))\n",
    "train['Phrase'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [intermittently, pleasing, mostly, routine, ef...\n",
       "1    [intermittently, pleasing, mostly, routine, ef...\n",
       "2                                                   []\n",
       "3    [intermittently, pleasing, mostly, routine, ef...\n",
       "4          [intermittently, pleasing, mostly, routine]\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Phrase']=test['Phrase'].apply(lambda x : tokenizer.tokenize(x.lower()))\n",
    "test['Phrase'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('series', 'NN'),\n",
       " ('escapades', 'VBZ'),\n",
       " ('demonstrating', 'JJ'),\n",
       " ('adage', 'NN'),\n",
       " ('good', 'JJ'),\n",
       " ('goose', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('gander', 'NN'),\n",
       " ('occasionally', 'RB'),\n",
       " ('amuses', 'VBZ'),\n",
       " ('none', 'NN'),\n",
       " ('amounts', 'NNS'),\n",
       " ('much', 'JJ'),\n",
       " ('story', 'NN')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train['Phrase'][0]\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Lemmatize the tokens:\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def word_lemma(text):\n",
    "    lem_text = ' '.join([lemmatizer.lemmatize(i) for i in text])\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     series escapade demonstrating adage good goose...\n",
       "1        series escapade demonstrating adage good goose\n",
       "2                                                series\n",
       "3                                                      \n",
       "4                                                series\n",
       "5               escapade demonstrating adage good goose\n",
       "6                                                      \n",
       "7               escapade demonstrating adage good goose\n",
       "8                                              escapade\n",
       "9                        demonstrating adage good goose\n",
       "10                                  demonstrating adage\n",
       "11                                        demonstrating\n",
       "12                                                adage\n",
       "13                                                     \n",
       "14                                                adage\n",
       "15                                           good goose\n",
       "16                                                     \n",
       "17                                           good goose\n",
       "18                                                     \n",
       "19                                           good goose\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Phrase']=train['Phrase'].apply(lambda x : word_lemma(x))\n",
    "train['Phrase'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         intermittently pleasing mostly routine effort\n",
       "1         intermittently pleasing mostly routine effort\n",
       "2                                                      \n",
       "3         intermittently pleasing mostly routine effort\n",
       "4                intermittently pleasing mostly routine\n",
       "5                               intermittently pleasing\n",
       "6                               intermittently pleasing\n",
       "7                                        intermittently\n",
       "8                                              pleasing\n",
       "9                                                      \n",
       "10                                       mostly routine\n",
       "11                                               mostly\n",
       "12                                              routine\n",
       "13                                               effort\n",
       "14                                                     \n",
       "15    kidman really thing worth watching birthday gi...\n",
       "16                                               kidman\n",
       "17    really thing worth watching birthday girl film...\n",
       "18    really thing worth watching birthday girl film...\n",
       "19                                               really\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Phrase']=test['Phrase'].apply(lambda x : word_lemma(x))\n",
    "test['Phrase'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def word_stem(text):\\n    stem_text = ' '.join([stemmer.stem (i) for i in text])\\n    return stem_text\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Stemming same as lemmatizing but little harsh:\n",
    "'''def word_stem(text):\n",
    "    stem_text = ' '.join([stemmer.stem (i) for i in text])\n",
    "    return stem_text'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Phrase']=df['Phrase'].apply(lambda x : word_stem(x))\n",
    "#df['Phrase'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object\n",
    "count_vectorizer = CountVectorizer(max_features=5000, analyzer='word', lowercase=False)\n",
    "# fit the count vectorizer using the text data\n",
    "#count_vectorizer.fit(df['Phrase'])\n",
    "# collect the vocabulary items used in the vectorizer\n",
    "#dictionary = count_vectorizer.vocabulary_.items()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 5000)\n",
      "(156060,)\n"
     ]
    }
   ],
   "source": [
    "# fit the count vectorizer\n",
    "X_vct = count_vectorizer.fit_transform(train['Phrase'])\n",
    "y = train['Sentiment']\n",
    "print(X_vct.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into Train Test data:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_vct,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaurav\\Anaconda3\\envs\\newroot\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing Logistic Regressoin as for Classification Problem :\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,y_train) # fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test) # predicting the value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  359,   644,   445,    49,     7],\n",
       "       [  262,  1828,  3032,   310,    21],\n",
       "       [   58,   829, 14016,  1031,    48],\n",
       "       [   14,   202,  3009,  2866,   350],\n",
       "       [    3,    26,   332,   957,   514]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the Confusion Matrix:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.74189414327823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.24      0.33      1504\n",
      "           1       0.52      0.34      0.41      5453\n",
      "           2       0.67      0.88      0.76     15982\n",
      "           3       0.55      0.44      0.49      6441\n",
      "           4       0.55      0.28      0.37      1832\n",
      "\n",
      "    accuracy                           0.63     31212\n",
      "   macro avg       0.56      0.44      0.47     31212\n",
      "weighted avg       0.61      0.63      0.60     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To show the accuarcy of the model \n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score ,classification_report\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred)*100) # To show the accuarcy of the model \n",
    "print(classification_report(y_test,y_pred)) # To show the classification report ie Precision, Recall , F1 score\n",
    " # log_reg.score(X, y) also for accuracy\n",
    "#print(\"Precision:\",precision_score(y_test, y_pred))\n",
    "#print(\"Recall:\",recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train) # fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =  clf.predict(X_test) # predicting the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.562475970780476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.44      0.43      1504\n",
      "           1       0.50      0.44      0.47      5453\n",
      "           2       0.71      0.80      0.75     15982\n",
      "           3       0.56      0.46      0.50      6441\n",
      "           4       0.50      0.38      0.43      1832\n",
      "\n",
      "    accuracy                           0.63     31212\n",
      "   macro avg       0.54      0.50      0.52     31212\n",
      "weighted avg       0.61      0.63      0.62     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred)*100) # To show the accuarcy of the model \n",
    "print(classification_report(y_test,y_pred)) # To show the classification report ie Precision, Recall , F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"min_samples_leaf\": list(range(1, 9)),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='entropy',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features=None,\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    presort='deprecated',\n",
       "                                                    random_state=None,\n",
       "                                                    splitter='best'),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [3, None],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "tree_cv = RandomizedSearchCV(clf, param_dist, cv=5)\n",
    "tree_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'gini'}\n",
      "Best score is 0.6142188610232315\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logreg = tree_cv.best_estimator_\n",
    "best_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Grid Search...\n",
      "accuary_score: 0.6253684480328079\n"
     ]
    }
   ],
   "source": [
    "y_gs_pred = best_logreg.predict(X_test)\n",
    "print(\"With Grid Search...\")\n",
    "print(f'accuary_score: {accuracy_score(y_test, y_gs_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO.of rows predicted: 66292\n",
      "[1 1 2 ... 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "X_vct_test = count_vectorizer.fit_transform(test['Phrase'])\n",
    "pred = clf.predict(X_vct_test)\n",
    "print(\"NO.of rows predicted:\" , len(pred))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing mostly routine effort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing mostly routine effort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing mostly routine effort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing mostly routine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                         Phrase  \\\n",
       "0    156061        8545  intermittently pleasing mostly routine effort   \n",
       "1    156062        8545  intermittently pleasing mostly routine effort   \n",
       "2    156063        8545                                                  \n",
       "3    156064        8545  intermittently pleasing mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing mostly routine   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          2  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Sentiment'] = pred\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    41577\n",
       "3    11284\n",
       "1    10515\n",
       "0     1778\n",
       "4     1138\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
