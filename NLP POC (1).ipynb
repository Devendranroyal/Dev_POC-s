{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the dataset & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import nltk_data\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk import tokenize\n",
    "#from nltk.corpus import stopwards\n",
    "#from nltk.tokenize import RegexTokenizer\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv(\"C:\\\\Users\\\\Milgram\\\\Desktop\\\\POC\\\\train.tsv\")\n",
    "df=pd.read_csv('C:\\\\Users\\\\Milgram\\\\Desktop\\\\POC\\\\train.tsv',delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('C:\\\\Users\\\\Milgram\\\\Desktop\\\\POC\\\\test.tsv',delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66292, 3)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Dealing With Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      0\n",
       "SentenceId    0\n",
       "Phrase        0\n",
       "Sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this step we will check the null values in our dataset and replace or drop as per the dataset\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      0\n",
       "SentenceId    0\n",
       "Phrase        0\n",
       "Sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this step we will remove all null values\n",
    "df.dropna(inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Labeling The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As per our dataset there is rating from 1 to 5. So, According to rating we will create there labels, Positive(for 1 & 2 Rating),\n",
    "#Neutral(for 3 Rating) and Negative (for 4,& 5 Rating).\n",
    "def LableFunc(Sentiment):\n",
    "    if Sentiment>=3:\n",
    "        return 'Positive'\n",
    "    elif Sentiment<=1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "df['Label']=df['Sentiment'].apply(LableFunc)\n",
    "#df1['Label']=df1['Sentiment'].apply(LableFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Neutral', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Negative\n",
       "1     Neutral\n",
       "2     Neutral\n",
       "3     Neutral\n",
       "4     Neutral\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Data Cleaning And Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Removing URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Phrase'].iloc[1]\n",
    "import  re\n",
    "\n",
    "def clean_url(Phrase_text):\n",
    "    return re.sub(r'http\\S+','',Phrase_text)\n",
    "\n",
    "df['CleanPhrase']=df['Phrase'].apply(clean_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A series of escapades demonstrating the adage ...\n",
       "1    A series of escapades demonstrating the adage ...\n",
       "2                                             A series\n",
       "3                                                    A\n",
       "4                                               series\n",
       "Name: CleanPhrase, dtype: object"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CleanPhrase'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Removing all irrelevant characters (Numbers and Punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_non_alphanumeric(Phrase_text):\n",
    "    return re.sub('[^a-zA-Z]','',Phrase_text)\n",
    "\n",
    "df['CleanPhrase']=df['CleanPhrase'].apply(clean_non_alphanumeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Aseriesofescapadesdemonstratingtheadagethatwha...\n",
       "1    Aseriesofescapadesdemonstratingtheadagethatwha...\n",
       "2                                              Aseries\n",
       "3                                                    A\n",
       "4                                               series\n",
       "Name: CleanPhrase, dtype: object"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CleanPhrase'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Convert all characters into lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lowercase(Phrase_text):\n",
    "    return str(Phrase_text).lower()\n",
    "\n",
    "df['CleanPhrase']=df['CleanPhrase'].apply(clean_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    aseriesofescapadesdemonstratingtheadagethatwha...\n",
       "1    aseriesofescapadesdemonstratingtheadagethatwha...\n",
       "2                                              aseries\n",
       "3                                                    a\n",
       "4                                               series\n",
       "Name: CleanPhrase, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CleanPhrase'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization is the process of splitting the given text into smaller pieces called tokens.\n",
    "#Words, numbers, punctuation marks, and others can be considered as tokens\n",
    "#We will use Natural language tool kit (nltk) library for tokenization.\n",
    "#Note: If we have data in the form of paragraphs, and we want to convert the paragraph into sentences, \n",
    "#then we will use nltk.sent_tokenize(paragraph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def clean_tokenization(Phrase_text):\n",
    "    return word_tokenize(Phrase_text)\n",
    "\n",
    "df['CleanPhrase']=df['CleanPhrase'].apply(clean_tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [aseriesofescapadesdemonstratingtheadagethatwh...\n",
       "1    [aseriesofescapadesdemonstratingtheadagethatwh...\n",
       "2                                            [aseries]\n",
       "3                                                  [a]\n",
       "4                                             [series]\n",
       "Name: CleanPhrase, dtype: object"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CleanPhrase'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V. Removing Stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#“Stopwords” are the most common words in a language like “the”, “a”, “me”, “is”, “to”, “all”,\n",
    "#These words do not carry important meaning and are usually removed from texts.\n",
    "#It is possible to remove stopwords using Natural Language Toolkit (nltk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the libraries required to remove the stopwords and punctuation\n",
    "from nltk.corpus import stopwords\n",
    "#let's look at the stopwords in english\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "def clean_stopwords(token):\n",
    "    return [item for item in token if item not in stop_words]\n",
    "\n",
    "df['CleanPhrase']=df['CleanPhrase'].apply(clean_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [aseriesofescapadesdemonstratingtheadagethatwh...\n",
       "1    [aseriesofescapadesdemonstratingtheadagethatwh...\n",
       "2                                            [aseries]\n",
       "3                                                   []\n",
       "4                                             [series]\n",
       "Name: CleanPhrase, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CleanPhrase'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VI. Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the inflectional forms of each word into a common base or root\n",
    "#Stemming usually refers to a crude process that chops off the ends of words in the hope of achieving this goal correctly most of the time\n",
    "# and often includes the removal of derivational units (the obtained element is known as the stem).\n",
    "# lemmatization consists in doing things properly with the use of a vocabulary and morphological analysis of words, \n",
    "#to return the base or dictionary form of a word, which is known as the lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def clean_stemtoken():\n",
    "    return [stemmer.stem(i) for i in token]\n",
    "\n",
    "#df['CleanPhrase']=df['CleanPhrase'].apply(clean_stemtoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['CleanPhrase']=df['CleanPhrase'].apply(clean_stemtoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "\n",
    "def clean_lemmatization(token):\n",
    "    return [lemma.lemmatize(word=w,pos='v') for w in token]\n",
    "\n",
    "#df['CleanPhrase']=df['CleanPhrase'].apply(clean_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['CleanPhrase']=df['CleanPhrase'].apply(clean_lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VII. Remove the words having length <= 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basically, after performing all required process in text processing there is some kind of noise is present in our corpus\n",
    "#so like that i am removing the words which have very short length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_length(token):\n",
    "    return [i for i in token if len(i)>2]\n",
    "\n",
    "df['CleanPhrase']=df['CleanPhrase'].apply(clean_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [aseriesofescapadesdemonstratingtheadagethatwh...\n",
       "1    [aseriesofescapadesdemonstratingtheadagethatwh...\n",
       "2                                            [aseries]\n",
       "3                                                   []\n",
       "4                                             [series]\n",
       "Name: CleanPhrase, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CleanPhrase'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words=set(stopwords.words('english'))\n",
    "lemma=WordNetLemmatizer()\n",
    "\n",
    "def clean_Phrase(phrase_text):\n",
    "    phrase_text=re.sub(r'http\\S+','',phrase_text)                             #removing the url\n",
    "    phrase_text=re.sub('[^a-zA-Z]','',phrase_text)                            #removing Numbers and punctuatino\n",
    "    phrase_text=str(phrase_text).lower()                                      #Convert all characters into lowercase\n",
    "    phrase_text=word_tokenize(phrase_text)                                    #Tokenization\n",
    "    phrase_text=[item for item in phrase_text if item not in stop_words]      #Removing Stop Words\n",
    "    phrase_text=[lemma.lemmatize(word=w,pos='v') for w in phrase_text]        #Lemmatization\n",
    "    phrase_text=[i for i in phrase_text if len(i)>2]                          #Remove the words havig length <=2\n",
    "    phrase_text=''.join(phrase_text)                                          #Converting list to string\n",
    "    return phrase_text\n",
    "\n",
    "df['clean_Phrase']=df['Phrase'].apply(clean_Phrase)\n",
    "df1['clean_Phrase']=df1['Phrase'].apply(clean_Phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    aseriesofescapadesdemonstratingtheadagethatwha...\n",
       "1    aseriesofescapadesdemonstratingtheadagethatwha...\n",
       "2                                              aseries\n",
       "3                                                     \n",
       "4                                               series\n",
       "Name: clean_Phrase, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_Phrase'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "      <th>CleanPhrase</th>\n",
       "      <th>clean_Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[aseriesofescapadesdemonstratingtheadagethatwh...</td>\n",
       "      <td>aseriesofescapadesdemonstratingtheadagethatwha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[aseriesofescapadesdemonstratingtheadagethatwh...</td>\n",
       "      <td>aseriesofescapadesdemonstratingtheadagethatwha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[aseries]</td>\n",
       "      <td>aseries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[series]</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[hearsts]</td>\n",
       "      <td>hearsts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[forcedavuncularchortles]</td>\n",
       "      <td>forcedavuncularchortles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[avuncularchortles]</td>\n",
       "      <td>avuncularchortles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[avuncular]</td>\n",
       "      <td>avuncular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[chortles]</td>\n",
       "      <td>chortle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \\\n",
       "0       A series of escapades demonstrating the adage ...          1   \n",
       "1       A series of escapades demonstrating the adage ...          2   \n",
       "2                                                A series          2   \n",
       "3                                                       A          2   \n",
       "4                                                  series          2   \n",
       "...                                                   ...        ...   \n",
       "156055                                          Hearst 's          2   \n",
       "156056                          forced avuncular chortles          1   \n",
       "156057                                 avuncular chortles          3   \n",
       "156058                                          avuncular          2   \n",
       "156059                                           chortles          2   \n",
       "\n",
       "           Label                                        CleanPhrase  \\\n",
       "0       Negative  [aseriesofescapadesdemonstratingtheadagethatwh...   \n",
       "1        Neutral  [aseriesofescapadesdemonstratingtheadagethatwh...   \n",
       "2        Neutral                                          [aseries]   \n",
       "3        Neutral                                                 []   \n",
       "4        Neutral                                           [series]   \n",
       "...          ...                                                ...   \n",
       "156055   Neutral                                          [hearsts]   \n",
       "156056  Negative                          [forcedavuncularchortles]   \n",
       "156057  Positive                                [avuncularchortles]   \n",
       "156058   Neutral                                        [avuncular]   \n",
       "156059   Neutral                                         [chortles]   \n",
       "\n",
       "                                             clean_Phrase  \n",
       "0       aseriesofescapadesdemonstratingtheadagethatwha...  \n",
       "1       aseriesofescapadesdemonstratingtheadagethatwha...  \n",
       "2                                                 aseries  \n",
       "3                                                          \n",
       "4                                                  series  \n",
       "...                                                   ...  \n",
       "156055                                            hearsts  \n",
       "156056                            forcedavuncularchortles  \n",
       "156057                                  avuncularchortles  \n",
       "156058                                          avuncular  \n",
       "156059                                            chortle  \n",
       "\n",
       "[156060 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    anintermittentlypleasingbutmostlyroutineeffort\n",
       "1    anintermittentlypleasingbutmostlyroutineeffort\n",
       "2                                                  \n",
       "3      intermittentlypleasingbutmostlyroutineeffort\n",
       "4            intermittentlypleasingbutmostlyroutine\n",
       "Name: clean_Phrase, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['clean_Phrase'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>clean_Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>anintermittentlypleasingbutmostlyroutineeffort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>anintermittentlypleasingbutmostlyroutineeffort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittentlypleasingbutmostlyroutineeffort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittentlypleasingbutmostlyroutine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66287</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "      <td>alongwindedpredictablescenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66288</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "      <td>alongwindedpredictablescenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66289</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "      <td>alongwinded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66290</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "      <td>alongwinded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66291</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "      <td>predictablescenario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66292 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId  \\\n",
       "0        156061        8545   \n",
       "1        156062        8545   \n",
       "2        156063        8545   \n",
       "3        156064        8545   \n",
       "4        156065        8545   \n",
       "...         ...         ...   \n",
       "66287    222348       11855   \n",
       "66288    222349       11855   \n",
       "66289    222350       11855   \n",
       "66290    222351       11855   \n",
       "66291    222352       11855   \n",
       "\n",
       "                                                  Phrase  \\\n",
       "0      An intermittently pleasing but mostly routine ...   \n",
       "1      An intermittently pleasing but mostly routine ...   \n",
       "2                                                     An   \n",
       "3      intermittently pleasing but mostly routine effort   \n",
       "4             intermittently pleasing but mostly routine   \n",
       "...                                                  ...   \n",
       "66287             A long-winded , predictable scenario .   \n",
       "66288               A long-winded , predictable scenario   \n",
       "66289                                    A long-winded ,   \n",
       "66290                                      A long-winded   \n",
       "66291                               predictable scenario   \n",
       "\n",
       "                                         clean_Phrase  \n",
       "0      anintermittentlypleasingbutmostlyroutineeffort  \n",
       "1      anintermittentlypleasingbutmostlyroutineeffort  \n",
       "2                                                      \n",
       "3        intermittentlypleasingbutmostlyroutineeffort  \n",
       "4              intermittentlypleasingbutmostlyroutine  \n",
       "...                                               ...  \n",
       "66287                  alongwindedpredictablescenario  \n",
       "66288                  alongwindedpredictablescenario  \n",
       "66289                                     alongwinded  \n",
       "66290                                     alongwinded  \n",
       "66291                             predictablescenario  \n",
       "\n",
       "[66292 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =df[['clean_Phrase','Sentiment','Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aseriesofescapadesdemonstratingtheadagethatwha...</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aseriesofescapadesdemonstratingtheadagethatwha...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aseries</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        clean_Phrase  Sentiment     Label\n",
       "0  aseriesofescapadesdemonstratingtheadagethatwha...          1  Negative\n",
       "1  aseriesofescapadesdemonstratingtheadagethatwha...          2   Neutral\n",
       "2                                            aseries          2   Neutral\n",
       "3                                                             2   Neutral\n",
       "4                                             series          2   Neutral"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing neutral sentiments\n",
    "train = train[train.Label != \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aseriesofescapadesdemonstratingtheadagethatwha...</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>goodforthegoose</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>thegandersomeofwhichoccasionallyamusesbutnoneo...</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>amuse</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_Phrase  Sentiment     Label\n",
       "0   aseriesofescapadesdemonstratingtheadagethatwha...          1  Negative\n",
       "21                                    goodforthegoose          3  Positive\n",
       "22                                               good          3  Positive\n",
       "33  thegandersomeofwhichoccasionallyamusesbutnoneo...          1  Negative\n",
       "46                                              amuse          3  Positive"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 44\n",
       "love                                              8\n",
       "suck                                              8\n",
       "inspire                                           7\n",
       "fail                                              7\n",
       "                                                 ..\n",
       "thatpeaceispossible                               1\n",
       "thebiggestproblemwithsatinrougeisliliaherself     1\n",
       "knowbetterthantorushtothetheatreforthisone        1\n",
       "gentlyhumorous                                    1\n",
       "misconstrue                                       1\n",
       "Name: clean_Phrase, Length: 66956, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['clean_Phrase'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =df[['clean_Phrase','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aseriesofescapadesdemonstratingtheadagethatwha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aseriesofescapadesdemonstratingtheadagethatwha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aseries</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        clean_Phrase  Sentiment\n",
       "0  aseriesofescapadesdemonstratingtheadagethatwha...          1\n",
       "1  aseriesofescapadesdemonstratingtheadagethatwha...          2\n",
       "2                                            aseries          2\n",
       "3                                                             2\n",
       "4                                             series          2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=df1[['clean_Phrase']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anintermittentlypleasingbutmostlyroutineeffort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anintermittentlypleasingbutmostlyroutineeffort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intermittentlypleasingbutmostlyroutineeffort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intermittentlypleasingbutmostlyroutine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     clean_Phrase\n",
       "0  anintermittentlypleasingbutmostlyroutineeffort\n",
       "1  anintermittentlypleasingbutmostlyroutineeffort\n",
       "2                                                \n",
       "3    intermittentlypleasingbutmostlyroutineeffort\n",
       "4          intermittentlypleasingbutmostlyroutine"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_features=6000, analyzer='word', lowercase=False)\n",
    "#cv = CountVectorizer()\n",
    "\n",
    "x=count_vectorizer.fit_transform(train['clean_Phrase'])\n",
    "#cv.fit(train)\n",
    "#X = cv.transform(train)\n",
    "y = train['Sentiment']\n",
    "#X_test = cv.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 6000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=21)\n",
    "\n",
    "# Model development and prediction - Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milgram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model with data\n",
    "\n",
    "logr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     7,  1449,     1,     0],\n",
       "       [    2,    40,  5417,     5,     0],\n",
       "       [    0,    13, 15710,   108,     0],\n",
       "       [    0,     3,  6303,   280,     1],\n",
       "       [    0,     0,  1782,    91,     0]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "y_pred = logr.predict(x_test)\n",
    "\n",
    "# Model Evaluation using Confusion Matrix - Logistic Regression\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     7  1449     1     0]\n",
      " [    2    40  5417     5     0]\n",
      " [    0    13 15710   108     0]\n",
      " [    0     3  6303   280     1]\n",
      " [    0     0  1782    91     0]]\n"
     ]
    }
   ],
   "source": [
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression model accuracy: 0.5135845187748302\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(\"LogisticRegression model accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1457\n",
      "           1       0.63      0.01      0.01      5464\n",
      "           2       0.51      0.99      0.68     15831\n",
      "           3       0.58      0.04      0.08      6587\n",
      "           4       0.00      0.00      0.00      1873\n",
      "\n",
      "    accuracy                           0.51     31212\n",
      "   macro avg       0.34      0.21      0.15     31212\n",
      "weighted avg       0.49      0.51      0.36     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score ,classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------DecisionTree Regression--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     7,  1449,     1,     0],\n",
       "       [    2,    40,  5417,     5,     0],\n",
       "       [    0,    13, 15710,   108,     0],\n",
       "       [    0,     3,  6303,   280,     1],\n",
       "       [    0,     0,  1782,    91,     0]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(x_train, y_train)\n",
    "clf_predict = clf.predict(x_test)\n",
    "\n",
    "# Model Evaluation using Confusion Matrix - DecisionTree Regression\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1457\n",
      "           1       0.63      0.01      0.01      5464\n",
      "           2       0.51      0.99      0.68     15831\n",
      "           3       0.58      0.04      0.08      6587\n",
      "           4       0.00      0.00      0.00      1873\n",
      "\n",
      "    accuracy                           0.51     31212\n",
      "   macro avg       0.34      0.21      0.15     31212\n",
      "weighted avg       0.49      0.51      0.36     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Regression model accuracy: 0.5135845187748302\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(\"DecisionTree Regression model accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------RandomForest Regression--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     7,  1450,     0,     0],\n",
       "       [    2,    40,  5418,     4,     0],\n",
       "       [    0,    13, 15728,    90,     0],\n",
       "       [    0,     3,  6353,   230,     1],\n",
       "       [    0,     0,  1792,    81,     0]], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfc = RandomForestRegressor()\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc_predict = rfc.predict(x_test)\n",
    "\n",
    "# Model Evaluation using Confusion Matrix - DecisionTree Regression\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1457\n",
      "           1       0.63      0.01      0.01      5464\n",
      "           2       0.51      0.99      0.68     15831\n",
      "           3       0.57      0.03      0.07      6587\n",
      "           4       0.00      0.00      0.00      1873\n",
      "\n",
      "    accuracy                           0.51     31212\n",
      "   macro avg       0.34      0.21      0.15     31212\n",
      "weighted avg       0.49      0.51      0.36     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Regression model accuracy: 0.512559272074843\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(\"RandomForest Regression model accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------Compute the IDF values-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_features=5000, analyzer='word', lowercase=False)\n",
    "#cv = CountVectorizer()\n",
    "\n",
    "x=count_vectorizer.fit_transform(train['clean_Phrase'])\n",
    "#cv.fit(train)\n",
    "#X = cv.transform(train)\n",
    "y = train['Sentiment']\n",
    "#X_test = cv.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 5000)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print idf values\n",
    "cv=CountVectorizer()\n",
    "#df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=train[\"clean_Phrase\"])\n",
    " \n",
    "# sort ascending\n",
    "#df_idf.sort_values(by=train['clean_Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------NLP DASHBOARD---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_file, output_notebook, push_notebook\n",
    "from bokeh.layouts import row, column, gridplot\n",
    "from bokeh.models import CustomJS, Slider\n",
    "from bokeh.palettes import Spectral6, Category20c\n",
    "from bokeh.palettes import Greys256,Inferno256,Magma256,Plasma256,Viridis256,Cividis256,Turbo256,linear_palette,Set3,Pastel1,Spectral5,Spectral6\n",
    "from bokeh.transform import factor_cmap, cumsum\n",
    "from bokeh.models.widgets import Paragraph,DataTable, TableColumn\n",
    "from bokeh.models import ColumnDataSource,HoverTool\n",
    "import numpy as np\n",
    "from bokeh.models.layouts import LayoutDOM, Box, Row, Column, GridBox, Spacer, WidgetBox\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_Phrase</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minutes</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minute</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>film</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yearold</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clean_Phrase  Count\n",
       "0                 694\n",
       "1      minutes     35\n",
       "2       minute     20\n",
       "3         film     14\n",
       "4      yearold     13"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtemp_fig = figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "windspeed_fig = figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = ' '\n",
    "stopwords = set(STOPWORDS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the csv file \n",
    "for val in df1['clean_Phrase']: \n",
    "      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "          \n",
    "    for words in tokens: \n",
    "        comment_words = comment_words + words + ' '\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 800, height = 800, max_words=30,\n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 2).generate(comment_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the WordCloud image                        \n",
    "p3=plt.figure(figsize = (4, 4), facecolor = None) \n",
    "p3=plt.imshow(wordcloud) \n",
    "p3=plt.axis(\"off\") \n",
    "p3=plt.tight_layout(pad = 0) \n",
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x220d0c0f9c8>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcloud.to_file(\"wc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x220d0c0f9c8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcloud.to_file(\"wc.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file(\"NLP_Dashboard.html\")\n",
    "tools=\"pan,wheel_zoom,box_zoom,reset,save,box_select,hover\"\n",
    "#p1 = Paragraph(text=\"\"\"\"\"\", width=400, height=100)\n",
    "\n",
    "#-Predective Analytics Data Analysis\n",
    "#p2 =Paragraph(text=\"\"\" Hyundai-Predective Analytics-EDA \"\"\", width=800, height=100, style={'font-size': '300%', 'color':'blue'},sizing_mode='fixed')\n",
    "p2 = Paragraph(text=\"\"\"Sentimental Analysis\"\"\", width=600, height=100, style={'font-size': '300%', 'color':'firebrick'})\n",
    "p3 = figure(plot_width=400, plot_height=400, title=\"WORDCOUNT\")\n",
    "# plot the WordCloud image                        \n",
    "#p3=plt.figure(figsize = (4, 4), facecolor = None) \n",
    "#p3=plt.imshow(wordcloud) \n",
    "#p3=plt.axis(\"off\") \n",
    "#p3=plt.tight_layout(pad = 0) \n",
    "p3.image_url(url=['C:\\\\Users\\\\Milgram\\\\wc.png'], x=0, y=0, w=0.8, h=0.8,anchor=\"bottom_left\")\n",
    "p3.xaxis.visible = None\n",
    "p3.yaxis.visible = None\n",
    "\n",
    "#p4 = figure(tools=\"pan,wheel_zoom,box_zoom,reset\")\n",
    "x=df['Sentiment'].value_counts()\n",
    "data = pd.Series(x).reset_index(name='Count').rename(columns={'index':'Sentiment'})\n",
    "#p4 = figure(tools=\"pan,wheel_zoom,box_zoom,reset\")\n",
    "p4 = figure(plot_width=400, plot_height=400,x_axis_label=\"Count of Each Sentiments\", y_axis_label=\"Count\",title=\"Count of Each Sentiments\", tools=tools,toolbar_location=\"right\" ,tooltips=[(\"Sentiment\",\"@x\"),(\"Count\",\"@top\")])\n",
    "p4.vbar(x=range(5), top=data['Count'], width=0.7,color=Spectral5,line_color=\"black\")\n",
    "#p4.y_range.start =0\n",
    "#p4.y_range.end = 30\n",
    "#p4.xaxis.major_label_orientation = pi/4\n",
    "#show(p4)\n",
    "\n",
    "x=df['Sentiment'].value_counts()\n",
    "data = pd.Series(x).reset_index(name='Count').rename(columns={'index':'Sentiment'})\n",
    "#data = pd.Series(x).reset_index(name='value').rename(columns={'index':'country'})\n",
    "data['angle'] = data['Count']/data['Count'].sum() * 2*pi\n",
    "data['percent'] = data['Count'] /data['Count'].sum() * 100\n",
    "data['color'] = Category20c[len(x)]\n",
    "p5 = figure(plot_height=400,plot_width=400, title=\"Percentage of each Sentiments\", toolbar_location=None,\n",
    "           tools=\"hover\", tooltips=\"@Sentiment: @percent{0.2f} %\", x_range=(-0.5, 1.0))\n",
    "p5.wedge(x=0, y=1, radius=0.4,\n",
    "        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "        line_color=\"white\", fill_color='color', legend_field='Sentiment', source=data)\n",
    "p5.axis.axis_label=None\n",
    "p5.axis.visible=False\n",
    "p5.grid.grid_line_color = None\n",
    "\n",
    "\n",
    "slider = Slider(start=0, end=4, value=1, step=1, title=\"Sentiment Slider\")\n",
    "#show(column([p3,p4,p5],[p6,p8,None]))\n",
    "col1 = row(p3,p4,p5)\n",
    "col2 =row(slider)\n",
    "col3 = row(p6,p3)\n",
    "col4 =row(p2)\n",
    "\n",
    "#col4 =row(p7)\n",
    "\n",
    "show(column(col4,col1,col2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------Practice----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['transaction percentage','CASH_IN', 'CASH_OUT', 'DEBIT', 'PAYMENT', 'TRANSFER', 'C', 'M']\n",
    "x = p[feature_cols]\n",
    "y = p.isFraud\n",
    "# Splitting data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=21)\n",
    "\n",
    "# Model development and prediction - Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with data\n",
    "\n",
    "logr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "y_pred = logr.predict(x_test)\n",
    "\n",
    "# Model Evaluation using Confusion Matrix - Logistic Regression\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "print(\"LogisticRegression model accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['clean_Phrase']\n",
    "y = train['Sentiment']\n",
    "# Splitting data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=21)\n",
    "\n",
    "# Model development and prediction - Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "train.isna().sum()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(train['clean_Phrase'])\n",
    "count_vector=cv.fit_transform(train['clean_Phrase'])\n",
    "count_vector.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   but  can  catch  drink  flies  him  honey  horse  lead  make  more  than  to  vinegar  water  with  you\n",
      "0    0    2      1      0      1    0      1      0     0     0     1     1   0        1      0     2    2\n",
      "1    1    2      0      1      0    1      0      1     1     1     0     0   1        0      1     0    2\n"
     ]
    }
   ],
   "source": [
    ">>> from pandas import DataFrame\n",
    ">>> from sklearn.feature_extraction.text import CountVectorizer\n",
    ">>> docs = [\"You can catch more flies with honey than you can with vinegar.\",\n",
    "...         \"You can lead a horse to water, but you can't make him drink.\"]\n",
    ">>> vect = CountVectorizer(min_df=0., max_df=1.0)\n",
    ">>> X = vect.fit_transform(docs)\n",
    ">>> print(DataFrame(X.A, columns=vect.get_feature_names()).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-243-a3f2ec5afeb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_Phrase'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mvect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5273\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5274\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    ">>> from pandas import DataFrame\n",
    ">>> from sklearn.feature_extraction.text import CountVectorizer\n",
    ">>> docs =train['clean_Phrase'].toarray()\n",
    ">>> vect = CountVectorizer(min_df=0., max_df=1.0)\n",
    ">>> X = vect.fit_transform(docs)\n",
    ">>> print(DataFrame(X.A, columns=vect.get_feature_names()).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-246-99128bfe9c8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Get feature names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# View feature names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "# Get feature names\n",
    "feature_names = count.get_feature_names()\n",
    "\n",
    "# View feature names\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "      <th>CleanPhrase</th>\n",
       "      <th>clean_Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[aseriesofescapadesdemonstratingtheadagethatwh...</td>\n",
       "      <td>aseriesofescapadesdemonstratingtheadagethatwha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[aseriesofescapadesdemonstratingtheadagethatwh...</td>\n",
       "      <td>aseriesofescapadesdemonstratingtheadagethatwha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[aseries]</td>\n",
       "      <td>aseries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[series]</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment     Label                                        CleanPhrase  \\\n",
       "0          1  Negative  [aseriesofescapadesdemonstratingtheadagethatwh...   \n",
       "1          2   Neutral  [aseriesofescapadesdemonstratingtheadagethatwh...   \n",
       "2          2   Neutral                                          [aseries]   \n",
       "3          2   Neutral                                                 []   \n",
       "4          2   Neutral                                           [series]   \n",
       "\n",
       "                                        clean_Phrase  \n",
       "0  aseriesofescapadesdemonstratingtheadagethatwha...  \n",
       "1  aseriesofescapadesdemonstratingtheadagethatwha...  \n",
       "2                                            aseries  \n",
       "3                                                     \n",
       "4                                             series  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(x).reset_index(name='Count').rename(columns={'index':'Sentiment'})\n",
    "#p4 = figure(tools=\"pan,wheel_zoom,box_zoom,reset\")\n",
    "p4 = figure(plot_width=400, plot_height=400,x_axis_label=\"Count of Each Sentiments\", y_axis_label=\"Count\",title=\"Count of Each Sentiments\", tools=tools,toolbar_location=\"right\" ,tooltips=[(\"Sentiment\",\"@x\"),(\"Count\",\"@top\")])\n",
    "p4.vbar(x=range(5), top=data['Count'], width=0.7,color=Spectral5)\n",
    "#p4.y_range.start =0\n",
    "#p4.y_range.end = 30\n",
    "#p4.xaxis.major_label_orientation = pi/4\n",
    "show(p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized range input: '[2 3 1 4 0]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-8f0c7d359cd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#df=data.head(8)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m p4 = figure(x_range=data['Sentiment'],plot_width=600, plot_height=600,x_axis_label=\"Sentiments\", \n\u001b[1;32m----> 6\u001b[1;33m             y_axis_label=\"Count\",title=\"Count of each Sentiments\",tools=tools,toolbar_location=None,tooltips=[(\"Sentiment\",\"@x\"),(\"Count\",\"@top\")])\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mp4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#p4.y_range.start = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\plotting\\figure.py\u001b[0m in \u001b[0;36mfigure\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\plotting\\figure.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *arg, **kw)\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\plotting\\helpers.py\u001b[0m in \u001b[0;36m_get_range\u001b[1;34m(range_input)\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# @mattpap suggests ValidationError instead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unrecognized range input: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized range input: '[2 3 1 4 0]'"
     ]
    }
   ],
   "source": [
    "data= pd.read_csv('C:\\\\Users\\\\Milgram\\\\Desktop\\\\POC\\\\train.tsv',delimiter='\\t',encoding='utf-8')\n",
    "x=data['Sentiment'].value_counts()\n",
    "data = pd.Series(x).reset_index(name='Count').rename(columns={'index':'Sentiment'})\n",
    "#df=data.head(8)\n",
    "p4 = figure(x_range=data['Sentiment'],plot_width=600, plot_height=600,x_axis_label=\"Sentiments\", \n",
    "            y_axis_label=\"Count\",title=\"Count of each Sentiments\",tools=tools,toolbar_location=None,tooltips=[(\"Sentiment\",\"@x\"),(\"Count\",\"@top\")])\n",
    "p4.vbar(x=data['Sentiment'], top=data['Count'], width=0.9)\n",
    "#p4.y_range.start = 0\n",
    "#p4.y_range.end = 30\n",
    "#p4.xaxis.major_label_orientation = pi/4\n",
    "#p4.xaxis.major_label_overrides = {'wf_SCHED_CTRLM_AM_QM_CAARS_INCR': '1', 'wf_SCHED_CTRLM_MDMSTG_MDM_PREFERENCE_GENESIS': '2', 'wf_SCHED_WARR_DAILY_CDC': '3', 'wf_SCHED_EBIZ_DAILY':'4', 'wf_SCHED_WEEKLY_SERVICE_DCRS_WARR_LOAD_GEN':'5', 'wf_SCHED_CTRLM_WEEKLY_EMAIL_KMA_ACXIOM':'6', 'wf_SCHED_CTRLM_DAILY_KMA_CDM_CRM_RDR_KMF_DV_EDQIN_ODS_INCR':'7', 'wf_SCHED_CTRLM_DAILY_KMA_CDM_MDM_ENTERPRISE':'8'}\n",
    "show(p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['Sentiment'].value_counts()\n",
    "data = pd.Series(x).reset_index(name='Count').rename(columns={'index':'Sentiment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>79582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>32927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>27273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment  Count\n",
       "0          2  79582\n",
       "1          3  32927\n",
       "2          1  27273\n",
       "3          4   9206\n",
       "4          0   7072"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "156060",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-dd762e980cf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#data = pd.Series(x).reset_index(name='value').rename(columns={'index':'country'})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'angle'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'color'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategory20c\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m p5 = figure(plot_height=400, title=\"Percentage of each Sentiments\", toolbar_location=None,\n\u001b[0;32m      6\u001b[0m            tools=\"hover\", tooltips=\"@Sentiment: @Count\", x_range=(-0.5, 1.0))\n",
      "\u001b[1;31mKeyError\u001b[0m: 156060"
     ]
    }
   ],
   "source": [
    "data = pd.Series(x).reset_index(name='Count').rename(columns={'index':'Sentiment'})\n",
    "#data = pd.Series(x).reset_index(name='value').rename(columns={'index':'country'})\n",
    "data['angle'] = data['Count']/data['Count'].sum() * 2*pi\n",
    "data['color'] = Category20c[len(x)]\n",
    "p5 = figure(plot_height=400, title=\"Percentage of each Sentiments\", toolbar_location=None,\n",
    "           tools=\"hover\", tooltips=\"@Sentiment: @Count\", x_range=(-0.5, 1.0))\n",
    "\n",
    "p5.wedge(x=0, y=1, radius=0.4,\n",
    "        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "        line_color=\"black\", fill_color='color', legend_field='Sentiment', source=data)\n",
    "\n",
    "p5.axis.axis_label=None\n",
    "p5.axis.visible=False\n",
    "p5.grid.grid_line_color = None\n",
    "\n",
    "#p8.xaxis.major_label_orientation = pi/4\n",
    "show(p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-154-7d23828fdc67>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-154-7d23828fdc67>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    data_table = (DataTable(source=source, columns=columns, width=600, height=400))\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x=df['clean_Phrase']\n",
    "data = pd.Series(x).reset_index(name='Count').rename(columns={'index':'clean_Phrase'})\n",
    "source = ColumnDataSource(data)\n",
    "columns = TableColumn(field=\"Sentiment\", title=\"Sentiment\",TableColumn(field=\"Count\", title=\"Count\")\n",
    "data_table = (DataTable(source=source, columns=columns, width=600, height=400))\n",
    "show(widgetbox(data_table))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected an instance of type DataSource, got   clean_Phrase  Count\n0                 694\n1      minutes     35\n2       minute     20\n3         film     14\n4      yearold     13\n5        years     12\n6         work     12\n7         time     12 of type DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-238-2c12cbce8d9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#TableColumn(field=\"Count\", title=\"Count\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mp6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\models\\widgets\\tables.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kw)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTableWidget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"view\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCDSView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m         \u001b[0mdefault_theme\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_to_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\has_props.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **properties)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m             \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\has_props.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprops\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdescriptor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHasProps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0mmatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdifflib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_close_matches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"similar\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\property\\descriptors.py\u001b[0m in \u001b[0;36m__set__\u001b[1;34m(self, obj, value, setter)\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.%s is a readonly property\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__delete__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\property\\descriptors.py\u001b[0m in \u001b[0;36m_internal_set\u001b[1;34m(self, obj, value, hint, setter)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         '''\n\u001b[1;32m--> 766\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\property\\bases.py\u001b[0m in \u001b[0;36mprepare_value\u001b[1;34m(self, obj_or_cls, name, value)\u001b[0m\n\u001b[0;32m    325\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\property\\bases.py\u001b[0m in \u001b[0;36mprepare_value\u001b[1;34m(self, obj_or_cls, name, value)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalidation_on\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malternatives\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\property\\instance.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, value, detail)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdetail\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"expected an instance of type %s, got %s of type %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_may_have_unstable_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: expected an instance of type DataSource, got   clean_Phrase  Count\n0                 694\n1      minutes     35\n2       minute     20\n3         film     14\n4      yearold     13\n5        years     12\n6         work     12\n7         time     12 of type DataFrame"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from random import randint\n",
    "\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models.widgets import DataTable, DateFormatter, TableColumn\n",
    "from bokeh.io import output_file, show\n",
    "\n",
    "x=df['clean_Phrase'].value_counts()\n",
    "data = pd.Series(x).reset_index(name='Count').rename(columns={'index':'clean_Phrase'}) \n",
    "df1=data.head(8)\n",
    "\n",
    "source = ColumnDataSource(df1)\n",
    "\n",
    "#columns = TableColumn(field=\"Sentiment\", title=\"Sentiment\",\n",
    "        #TableColumn(field=\"Count\", title=\"Count\")\n",
    "\n",
    "p6 = DataTable(source=df1,columns=df1.columns, width=600, height=400)\n",
    "\n",
    "show(p6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_Phrase</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minutes</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minute</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>film</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yearold</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>years</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>work</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>time</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clean_Phrase  Count\n",
       "0                 694\n",
       "1      minutes     35\n",
       "2       minute     20\n",
       "3         film     14\n",
       "4      yearold     13\n",
       "5        years     12\n",
       "6         work     12\n",
       "7         time     12"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df['clean_Phrase'].value_counts()\n",
    "data = pd.Series(x).reset_index(name='Count').rename(columns={'index':'clean_Phrase'}) \n",
    "df1=data.head(8)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "        TableColumn(field=\"clean_Phrase\", title=\"Sentiment\", formatter=DateFormatter()),\n",
    "        TableColumn(field=\"Count\", title=\"Count\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected an instance of type DataSource, got   clean_Phrase  Count\n0                 694\n1      minutes     35\n2       minute     20\n3         film     14\n4      yearold     13\n5        years     12\n6         work     12\n7         time     12 of type DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-229-ef23042942ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\models\\widgets\\tables.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kw)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTableWidget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"view\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCDSView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m         \u001b[0mdefault_theme\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_to_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\has_props.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **properties)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m             \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\has_props.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprops\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdescriptor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHasProps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0mmatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdifflib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_close_matches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"similar\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\property\\descriptors.py\u001b[0m in \u001b[0;36m__set__\u001b[1;34m(self, obj, value, setter)\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.%s is a readonly property\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__delete__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\property\\descriptors.py\u001b[0m in \u001b[0;36m_internal_set\u001b[1;34m(self, obj, value, hint, setter)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         '''\n\u001b[1;32m--> 766\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\property\\bases.py\u001b[0m in \u001b[0;36mprepare_value\u001b[1;34m(self, obj_or_cls, name, value)\u001b[0m\n\u001b[0;32m    325\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\property\\bases.py\u001b[0m in \u001b[0;36mprepare_value\u001b[1;34m(self, obj_or_cls, name, value)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalidation_on\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malternatives\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bokeh\\core\\property\\instance.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, value, detail)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdetail\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"expected an instance of type %s, got %s of type %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_may_have_unstable_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: expected an instance of type DataSource, got   clean_Phrase  Count\n0                 694\n1      minutes     35\n2       minute     20\n3         film     14\n4      yearold     13\n5        years     12\n6         work     12\n7         time     12 of type DataFrame"
     ]
    }
   ],
   "source": [
    "p6 = DataTable(source=df1, columns=columns, width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "\n",
    "output_file('stackoverflow.html')\n",
    "p1 = figure()\n",
    "p1.line(x=range(5), y=range(5))\n",
    "tab1 = Panel(child=p1, title=\"Box Line Plot\")\n",
    "tabs = Tabs(tabs=[tab1])\n",
    "show(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x220d174f0c8>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "teststring = 'hi this is a test test test test test string for a word cloud'\n",
    "wordcloud = WordCloud(width=1000, height=1000, margin=0, background_color='white', \n",
    "                      collocations=False).generate(teststring)\n",
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
